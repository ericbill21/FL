# Federated Learning: An Investigation of Weaknesses, Countermeasures, and Attacks

## Abstract
Federated Learning (FL) is a novel approach to distributed, scalable, and privacy-preserving machine learning. However, these very characteristics make it vulnerable to various attacks, including the class of model poisoning attacks.
In this work, we will classify attacks on FL in general into coarse categories and highlight the associated vulnerabilities of FL against each category. In particular, we will explore the underlying mechanism of model poisoning attacks in detail by examining common countermeasures that have been proposed to mitigate these attacks but are still vulnerable to modern attacks. With these findings, we conclude the paper by saying that countermeasures are just a form of statistical outlier detection, that some countermeasures risk leaking sensitive private data, and that most countermeasures do not slow down the training process.
